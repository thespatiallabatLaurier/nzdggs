{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Installing Documentations of NZDGGS package to work with Netezza Database. Manipulate and Run Analysis on Netezza Using IDEAS Model Documentations https://rdrr.io/github/am2222/nzdggs/ https://nzdggs.readthedocs.io/en/latest/ Install devtools :: install_github ( \"am2222/nzdggs\" ) Examples Getting Started Convert and Importing Data Polygon To DGGS .Nc to DGGS API","title":"Installing"},{"location":"#installing","text":"Documentations of NZDGGS package to work with Netezza Database. Manipulate and Run Analysis on Netezza Using IDEAS Model","title":"Installing"},{"location":"#documentations","text":"https://rdrr.io/github/am2222/nzdggs/ https://nzdggs.readthedocs.io/en/latest/","title":"Documentations"},{"location":"#install","text":"devtools :: install_github ( \"am2222/nzdggs\" )","title":"Install"},{"location":"#examples","text":"Getting Started Convert and Importing Data Polygon To DGGS .Nc to DGGS API","title":"Examples"},{"location":"Api/ImporterClass/","text":"ImporterClass : Data imported Class Description Class to import text files into netezza db using external table Examples ``` ```","title":"`ImporterClass`: Data imported Class"},{"location":"Api/ImporterClass/#importerclass-data-imported-class","text":"","title":"ImporterClass: Data imported Class"},{"location":"Api/ImporterClass/#description","text":"Class to import text files into netezza db using external table","title":"Description"},{"location":"Api/ImporterClass/#examples","text":"``` ```","title":"Examples"},{"location":"Api/nz_convert_datetime_to_tid/","text":"nz_convert_datetime_to_tid : Convert Datetime To Tid Description Converts a data and time object to tid. Use this function to make a datatime object strptime( '02-01-1980 00:00:00', \"%d-%m-%Y %H:%M:%S\") Usage nz_convert_datetime_to_tid ( datetime , scale ) Arguments Argument Description datetime a date and time value in string format like '2016-01-02 00:00:00'. It must be between \"1000-01-01 00:00:00\" and \"3000-01-01 00:00:00\" scale the scale for TID. Must be one the following items '1000y','500y','100y','50y','10y','1y','m','w','d','12h','6h','3h','h','min','s' Value TID in an Integer format Examples convert_datetime_to_tid ( strptime ( '02-01-1980 00:00:00' , \"%d-%m-%Y %H:%M:%S\" ), '1y' ) #Another Example start <- as.Date ( \"01-01-1980\" , format = \"%d-%m-%Y\" ) end <- as.Date ( \"01-01-2020\" , format = \"%d-%m-%Y\" ) theDate <- startdf <- data.frame () names ( df ) <- c ( \"time\" , \"tid\" ) while ( theDate <= end ) { t <- strptime ( paste ( format ( theDate , \"%d-%m-%Y\" ), \" 00:00:00\" ), \"%d-%m-%Y %H:%M:%S\" ) tid <- convert_datetime_to_tid ( t , \"d\" ) print ( tid ) df <- rbind ( df , data.frame ( time = t , tid = tid )) theDate <- seq.Date ( theDate , length = 2 , by = '1 years' )[ 2 ] }","title":"`nz_convert_datetime_to_tid`: Convert Datetime To Tid"},{"location":"Api/nz_convert_datetime_to_tid/#nz_convert_datetime_to_tid-convert-datetime-to-tid","text":"","title":"nz_convert_datetime_to_tid: Convert Datetime To Tid"},{"location":"Api/nz_convert_datetime_to_tid/#description","text":"Converts a data and time object to tid. Use this function to make a datatime object strptime( '02-01-1980 00:00:00', \"%d-%m-%Y %H:%M:%S\")","title":"Description"},{"location":"Api/nz_convert_datetime_to_tid/#usage","text":"nz_convert_datetime_to_tid ( datetime , scale )","title":"Usage"},{"location":"Api/nz_convert_datetime_to_tid/#arguments","text":"Argument Description datetime a date and time value in string format like '2016-01-02 00:00:00'. It must be between \"1000-01-01 00:00:00\" and \"3000-01-01 00:00:00\" scale the scale for TID. Must be one the following items '1000y','500y','100y','50y','10y','1y','m','w','d','12h','6h','3h','h','min','s'","title":"Arguments"},{"location":"Api/nz_convert_datetime_to_tid/#value","text":"TID in an Integer format","title":"Value"},{"location":"Api/nz_convert_datetime_to_tid/#examples","text":"convert_datetime_to_tid ( strptime ( '02-01-1980 00:00:00' , \"%d-%m-%Y %H:%M:%S\" ), '1y' ) #Another Example start <- as.Date ( \"01-01-1980\" , format = \"%d-%m-%Y\" ) end <- as.Date ( \"01-01-2020\" , format = \"%d-%m-%Y\" ) theDate <- startdf <- data.frame () names ( df ) <- c ( \"time\" , \"tid\" ) while ( theDate <= end ) { t <- strptime ( paste ( format ( theDate , \"%d-%m-%Y\" ), \" 00:00:00\" ), \"%d-%m-%Y %H:%M:%S\" ) tid <- convert_datetime_to_tid ( t , \"d\" ) print ( tid ) df <- rbind ( df , data.frame ( time = t , tid = tid )) theDate <- seq.Date ( theDate , length = 2 , by = '1 years' )[ 2 ] }","title":"Examples"},{"location":"Api/nz_convert_df_to_dggs/","text":"nz_convert_df_to_dggs : dataframe to dggs Description Converts a dataframe with a DGGID/TID column and set of other columns (keys) to csv datasets to be able to import them into netezza. You can import csv files to the database using nz_import_dir_to_db function Usage nz_convert_df_to_dggs ( DGGID , TID , df , SaveIn , convertKeys = \"all\" ) Arguments Argument Description DGGID A dataframe column containing DGGIDs TID An integer or dataframe column df dataframe with the remaining keys. Remove DGGID/TID columns from it SaveIn The directory path to store data there. It must exist convertKeys Keys that are supposed to be converted. all means converting all the keys. NA means does not convert any keys.Use a vector of column names to only convert specific keys Value Examples csv <- read.csv2 ( \"D:\\\\UserData\\\\Majid\\\\Downloads\\\\mpb-ev.csv\" , sep = \",\" ) head ( csv ) nz_convert_df_to_dggs ( csv $ DGGID , -1 , csv , \"E:\\\\home\\\\crobertson\" ) \\ #importing to the db DSN <- nz_init ( \"NZSQLF\" , \"SPATIAL_SCHEMA\" ) nz_import_dir_to_db ( DSN , \"/home/crobertson/import/\" , \"mbpev\" , \"varchar(100)\" )","title":"`nz_convert_df_to_dggs`: dataframe to dggs"},{"location":"Api/nz_convert_df_to_dggs/#nz_convert_df_to_dggs-dataframe-to-dggs","text":"","title":"nz_convert_df_to_dggs: dataframe to dggs"},{"location":"Api/nz_convert_df_to_dggs/#description","text":"Converts a dataframe with a DGGID/TID column and set of other columns (keys) to csv datasets to be able to import them into netezza. You can import csv files to the database using nz_import_dir_to_db function","title":"Description"},{"location":"Api/nz_convert_df_to_dggs/#usage","text":"nz_convert_df_to_dggs ( DGGID , TID , df , SaveIn , convertKeys = \"all\" )","title":"Usage"},{"location":"Api/nz_convert_df_to_dggs/#arguments","text":"Argument Description DGGID A dataframe column containing DGGIDs TID An integer or dataframe column df dataframe with the remaining keys. Remove DGGID/TID columns from it SaveIn The directory path to store data there. It must exist convertKeys Keys that are supposed to be converted. all means converting all the keys. NA means does not convert any keys.Use a vector of column names to only convert specific keys","title":"Arguments"},{"location":"Api/nz_convert_df_to_dggs/#value","text":"","title":"Value"},{"location":"Api/nz_convert_df_to_dggs/#examples","text":"csv <- read.csv2 ( \"D:\\\\UserData\\\\Majid\\\\Downloads\\\\mpb-ev.csv\" , sep = \",\" ) head ( csv ) nz_convert_df_to_dggs ( csv $ DGGID , -1 , csv , \"E:\\\\home\\\\crobertson\" ) \\ #importing to the db DSN <- nz_init ( \"NZSQLF\" , \"SPATIAL_SCHEMA\" ) nz_import_dir_to_db ( DSN , \"/home/crobertson/import/\" , \"mbpev\" , \"varchar(100)\" )","title":"Examples"},{"location":"Api/nz_convert_points_df_to_dggs/","text":"nz_convert_points_df_to_dggs : Convert Point to DGGS Description Converts a set of x and y coordinates to DGGS data model. Usage nz_convert_points_df_to_dggs ( lat , lon , tid , res , df , save_in ) Arguments Argument Description lat y coordinates of the points (EPSG:4326) lon x coordinates of the points (EPSG:4326) tid TID value, A single integer for all data or a list of integer values res Resolution of the final dggs cells, a single integer value or a list of integer values df A dataframe of keys. The number of rows of this dataframe must be equal to the lat,lon rows save_in the directory to store outpur csv files. make sure that this directory exist, you have write permission and engough disc space Value Data are stored in save_in directory The csv files are per each key. Examples r <- read.csv ( 'D:/Bathurst_caribou_collars.csv' ) nz_convert_points_df_to_dggs ( r $ Latitude , r $ Latitude , 10 , 20 , r , \\ \"C:/result\" )","title":"`nz_convert_points_df_to_dggs`: Convert Point to DGGS"},{"location":"Api/nz_convert_points_df_to_dggs/#nz_convert_points_df_to_dggs-convert-point-to-dggs","text":"","title":"nz_convert_points_df_to_dggs: Convert Point to DGGS"},{"location":"Api/nz_convert_points_df_to_dggs/#description","text":"Converts a set of x and y coordinates to DGGS data model.","title":"Description"},{"location":"Api/nz_convert_points_df_to_dggs/#usage","text":"nz_convert_points_df_to_dggs ( lat , lon , tid , res , df , save_in )","title":"Usage"},{"location":"Api/nz_convert_points_df_to_dggs/#arguments","text":"Argument Description lat y coordinates of the points (EPSG:4326) lon x coordinates of the points (EPSG:4326) tid TID value, A single integer for all data or a list of integer values res Resolution of the final dggs cells, a single integer value or a list of integer values df A dataframe of keys. The number of rows of this dataframe must be equal to the lat,lon rows save_in the directory to store outpur csv files. make sure that this directory exist, you have write permission and engough disc space","title":"Arguments"},{"location":"Api/nz_convert_points_df_to_dggs/#value","text":"Data are stored in save_in directory The csv files are per each key.","title":"Value"},{"location":"Api/nz_convert_points_df_to_dggs/#examples","text":"r <- read.csv ( 'D:/Bathurst_caribou_collars.csv' ) nz_convert_points_df_to_dggs ( r $ Latitude , r $ Latitude , 10 , 20 , r , \\ \"C:/result\" )","title":"Examples"},{"location":"Api/nz_convert_points_key_value_to_dggs/","text":"nz_convert_points_key_value_to_dggs : Convert lat,lon, tid, key,value to a dggs data model Description Convert lat,lon, tid, key,value to a dggs data model Usage nz_convert_points_key_value_to_dggs ( lat , lon , tid , res , key , value , save_in ) Arguments Argument Description lat y coordinates of the points (EPSG:4326) lon x coordinates of the points (EPSG:4326) tid TID value, A single integer for all data or a list of integer values res Resolution of the final dggs cells, a single integer value or a list of integer values key a single string as key value a list of value with the length equal to the lat save_in the directory to store outpur csv files.make sure that this directory exist, you have write permission and engough disc space df A dataframe of keys. The number of rows of this dataframe must be equal to the lat,lon rows Value Examples r <- read.csv ( 'D:/Bathurst_caribou_collars.csv' ) nz_convert_points_key_value_to_dggs ( r $ Latitude , r $ Longitude , 100 , 10 , \\ \" key\\ \" , value , \\ \" C:/result\\ \" )","title":"`nz_convert_points_key_value_to_dggs`: Convert lat,lon, tid, key,value to a dggs data model"},{"location":"Api/nz_convert_points_key_value_to_dggs/#nz_convert_points_key_value_to_dggs-convert-latlon-tid-keyvalue-to-a-dggs-data-model","text":"","title":"nz_convert_points_key_value_to_dggs: Convert lat,lon, tid, key,value to a dggs data model"},{"location":"Api/nz_convert_points_key_value_to_dggs/#description","text":"Convert lat,lon, tid, key,value to a dggs data model","title":"Description"},{"location":"Api/nz_convert_points_key_value_to_dggs/#usage","text":"nz_convert_points_key_value_to_dggs ( lat , lon , tid , res , key , value , save_in )","title":"Usage"},{"location":"Api/nz_convert_points_key_value_to_dggs/#arguments","text":"Argument Description lat y coordinates of the points (EPSG:4326) lon x coordinates of the points (EPSG:4326) tid TID value, A single integer for all data or a list of integer values res Resolution of the final dggs cells, a single integer value or a list of integer values key a single string as key value a list of value with the length equal to the lat save_in the directory to store outpur csv files.make sure that this directory exist, you have write permission and engough disc space df A dataframe of keys. The number of rows of this dataframe must be equal to the lat,lon rows","title":"Arguments"},{"location":"Api/nz_convert_points_key_value_to_dggs/#value","text":"","title":"Value"},{"location":"Api/nz_convert_points_key_value_to_dggs/#examples","text":"r <- read.csv ( 'D:/Bathurst_caribou_collars.csv' ) nz_convert_points_key_value_to_dggs ( r $ Latitude , r $ Longitude , 100 , 10 , \\ \" key\\ \" , value , \\ \" C:/result\\ \" )","title":"Examples"},{"location":"Api/nz_convert_polygon_to_dggs/","text":"nz_convert_polygon_to_dggs : Convert Polygon to DGGS Description Converts a single polygon feature to a dggs data model and stores the results as csv files. This function loops over attributes and stores each attributes data as well. Usage nz_convert_polygon_to_dggs ( SpatialPolygonsDataFrame , Resolution , TID , PolygonID , SaveIn , convertKeys = \"all\" ) Arguments Argument Description SpatialPolygonsDataFrame a SpatialPolygonsDataFrame Object. SRC of input file must be EPSG:4326 Resolution the resolution of DGGS. An integer value. Higher values for large polygons takes long times to run TID TID value, an integer value exported from nz_convert_datetim_to_tid function PolygonID The unique id of polygon. it is only used to store csv file with a unique name to avoid csv overwrite SaveIn the directory to store csv files. It Must end with / convertKeys Keys that are supposed to be converted. all means converting all the keys. NA means does not convert any keys.Use a vector of column names to only convert specific keys Value Examples zones = readOGR ( \"ecozones.shp\" ) \\ n \", \" for ( i in seq ( 1 , length ( zones ))) i = 1 print ( i ) z = zones [ i ,] nz_convert_polygon_to_dggs ( z , 1 , 12 , i , 'D:/UserData/Majid/Desktop/PLOTS/' ) library ( \"nzdggs\" ) library ( \"stampr\" ) data ( mpb ) mpb $ dt <- Sys.Date () \\ n \", \" mpb $ YR <- mpb $ TGROUP +1996 mpb $ dt <- as.Date ( paste ( mpb $ YR , '-01-01' , sep = \"\" ), \"%Y-%m-%d\" ) mpb $ tid <- nz_convert_datetime_to_tid ( mpb $ dt , '1y' ) proj4string ( mpb ) <- '+proj=aea +lat_1=50 +lat_2=58.5 +lat_0=45 +lon_0=-126 +x_0=1000000 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs' mpb <- spTransform ( mpb , CRS ( \"+init=epsg:4326\" ) mpb <- mpb [, c ( 1 , 6 )] for ( i in seq ( 1 , length ( mpb ))){ z = mpb [ i ,] nz_convert_polygon_to_dggs ( z , 20 , z $ tid , z $ ID , \"E:\\\\\\\\home\\\\\\\\crobertson\\\\\\\\\" ) } DSN <- nz_init ( \"NZSQL\" , \"SPATIAL_SCHEMA\" ) nz_import_file_to_db ( DSN , \"E:/home/majid/cmb/cmb.csv\" , \"mpb\" , \"double\" , T , max_errors = 4400 )","title":"`nz_convert_polygon_to_dggs`: Convert Polygon to DGGS"},{"location":"Api/nz_convert_polygon_to_dggs/#nz_convert_polygon_to_dggs-convert-polygon-to-dggs","text":"","title":"nz_convert_polygon_to_dggs: Convert Polygon to DGGS"},{"location":"Api/nz_convert_polygon_to_dggs/#description","text":"Converts a single polygon feature to a dggs data model and stores the results as csv files. This function loops over attributes and stores each attributes data as well.","title":"Description"},{"location":"Api/nz_convert_polygon_to_dggs/#usage","text":"nz_convert_polygon_to_dggs ( SpatialPolygonsDataFrame , Resolution , TID , PolygonID , SaveIn , convertKeys = \"all\" )","title":"Usage"},{"location":"Api/nz_convert_polygon_to_dggs/#arguments","text":"Argument Description SpatialPolygonsDataFrame a SpatialPolygonsDataFrame Object. SRC of input file must be EPSG:4326 Resolution the resolution of DGGS. An integer value. Higher values for large polygons takes long times to run TID TID value, an integer value exported from nz_convert_datetim_to_tid function PolygonID The unique id of polygon. it is only used to store csv file with a unique name to avoid csv overwrite SaveIn the directory to store csv files. It Must end with / convertKeys Keys that are supposed to be converted. all means converting all the keys. NA means does not convert any keys.Use a vector of column names to only convert specific keys","title":"Arguments"},{"location":"Api/nz_convert_polygon_to_dggs/#value","text":"","title":"Value"},{"location":"Api/nz_convert_polygon_to_dggs/#examples","text":"zones = readOGR ( \"ecozones.shp\" ) \\ n \", \" for ( i in seq ( 1 , length ( zones ))) i = 1 print ( i ) z = zones [ i ,] nz_convert_polygon_to_dggs ( z , 1 , 12 , i , 'D:/UserData/Majid/Desktop/PLOTS/' ) library ( \"nzdggs\" ) library ( \"stampr\" ) data ( mpb ) mpb $ dt <- Sys.Date () \\ n \", \" mpb $ YR <- mpb $ TGROUP +1996 mpb $ dt <- as.Date ( paste ( mpb $ YR , '-01-01' , sep = \"\" ), \"%Y-%m-%d\" ) mpb $ tid <- nz_convert_datetime_to_tid ( mpb $ dt , '1y' ) proj4string ( mpb ) <- '+proj=aea +lat_1=50 +lat_2=58.5 +lat_0=45 +lon_0=-126 +x_0=1000000 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs' mpb <- spTransform ( mpb , CRS ( \"+init=epsg:4326\" ) mpb <- mpb [, c ( 1 , 6 )] for ( i in seq ( 1 , length ( mpb ))){ z = mpb [ i ,] nz_convert_polygon_to_dggs ( z , 20 , z $ tid , z $ ID , \"E:\\\\\\\\home\\\\\\\\crobertson\\\\\\\\\" ) } DSN <- nz_init ( \"NZSQL\" , \"SPATIAL_SCHEMA\" ) nz_import_file_to_db ( DSN , \"E:/home/majid/cmb/cmb.csv\" , \"mpb\" , \"double\" , T , max_errors = 4400 )","title":"Examples"},{"location":"Api/nz_convert_raster_to_dggs_by_centroid/","text":"nz_convert_raster_to_dggs_by_centroid : Raster to dggs Description Convert Raster object to dggs by centroids. You have to save csv file by yourself.Like using which write.csv(df2,name,sep=';', row.names=FALSE,) Usage nz_convert_raster_to_dggs_by_centroid ( rast , centroids , key , tid ) Arguments Argument Description rast Raster Object exported from Raster package centroids centroids dg made by nz_make_centroids_df_from_csv function key key tid tid value Value A dataframe object","title":"`nz_convert_raster_to_dggs_by_centroid`: Raster to dggs"},{"location":"Api/nz_convert_raster_to_dggs_by_centroid/#nz_convert_raster_to_dggs_by_centroid-raster-to-dggs","text":"","title":"nz_convert_raster_to_dggs_by_centroid: Raster to dggs"},{"location":"Api/nz_convert_raster_to_dggs_by_centroid/#description","text":"Convert Raster object to dggs by centroids. You have to save csv file by yourself.Like using which write.csv(df2,name,sep=';', row.names=FALSE,)","title":"Description"},{"location":"Api/nz_convert_raster_to_dggs_by_centroid/#usage","text":"nz_convert_raster_to_dggs_by_centroid ( rast , centroids , key , tid )","title":"Usage"},{"location":"Api/nz_convert_raster_to_dggs_by_centroid/#arguments","text":"Argument Description rast Raster Object exported from Raster package centroids centroids dg made by nz_make_centroids_df_from_csv function key key tid tid value","title":"Arguments"},{"location":"Api/nz_convert_raster_to_dggs_by_centroid/#value","text":"A dataframe object","title":"Value"},{"location":"Api/nz_dplyr_to_netezza/","text":"nz_dplyr_to_netezza : dplyr to Netezza table Description Save a dplyr object as netezza table. It can drop table when it already exists. Usage nz_dplyr_to_netezza ( DSN , dplyr , outputTable , dropIfExist = F ) Arguments Argument Description DSN A DSN object exported from nz_init function dplyr a dplyr object outputTable name of the output table to store data dropIfExist Drop if the outputTable does exist. Default is False. Use it with cautious since it removes data in the existing outputTable permanently Value A dplyr object from outputTable Examples DSN <- nz_init ( \"NZSQL\" , \"ADMIN\" ) mbp <- nz_table_as_dplyr ( DSN , \"MPB\" ) head ( mbp ) mbp2 <- nz_dplyr_to_netezza ( DSN , mbp , \"mbp2\" ) head ( mbp2 )","title":"`nz_dplyr_to_netezza`: dplyr to Netezza table"},{"location":"Api/nz_dplyr_to_netezza/#nz_dplyr_to_netezza-dplyr-to-netezza-table","text":"","title":"nz_dplyr_to_netezza: dplyr to Netezza table"},{"location":"Api/nz_dplyr_to_netezza/#description","text":"Save a dplyr object as netezza table. It can drop table when it already exists.","title":"Description"},{"location":"Api/nz_dplyr_to_netezza/#usage","text":"nz_dplyr_to_netezza ( DSN , dplyr , outputTable , dropIfExist = F )","title":"Usage"},{"location":"Api/nz_dplyr_to_netezza/#arguments","text":"Argument Description DSN A DSN object exported from nz_init function dplyr a dplyr object outputTable name of the output table to store data dropIfExist Drop if the outputTable does exist. Default is False. Use it with cautious since it removes data in the existing outputTable permanently","title":"Arguments"},{"location":"Api/nz_dplyr_to_netezza/#value","text":"A dplyr object from outputTable","title":"Value"},{"location":"Api/nz_dplyr_to_netezza/#examples","text":"DSN <- nz_init ( \"NZSQL\" , \"ADMIN\" ) mbp <- nz_table_as_dplyr ( DSN , \"MPB\" ) head ( mbp ) mbp2 <- nz_dplyr_to_netezza ( DSN , mbp , \"mbp2\" ) head ( mbp2 )","title":"Examples"},{"location":"Api/nz_export_centroids_from_db/","text":"nz_export_centroids_from_db : Export centroids Description Export centroids from Netezza FinalGrid table for specific resolution. Usage nz_export_centroids_from_db ( DSN , output_directory , resolution ) Arguments Argument Description DSN NZODBC DSN object made by nz_init function output_directory The output directory to store csv file (like F:\\data\\store)it should be available on the disc resolution the resolution of the data Value","title":"`nz_export_centroids_from_db`: Export centroids"},{"location":"Api/nz_export_centroids_from_db/#nz_export_centroids_from_db-export-centroids","text":"","title":"nz_export_centroids_from_db: Export centroids"},{"location":"Api/nz_export_centroids_from_db/#description","text":"Export centroids from Netezza FinalGrid table for specific resolution.","title":"Description"},{"location":"Api/nz_export_centroids_from_db/#usage","text":"nz_export_centroids_from_db ( DSN , output_directory , resolution )","title":"Usage"},{"location":"Api/nz_export_centroids_from_db/#arguments","text":"Argument Description DSN NZODBC DSN object made by nz_init function output_directory The output directory to store csv file (like F:\\data\\store)it should be available on the disc resolution the resolution of the data","title":"Arguments"},{"location":"Api/nz_export_centroids_from_db/#value","text":"","title":"Value"},{"location":"Api/nz_find_duplicates/","text":"nz_find_duplicates : Find duplicates Description Find duplicate cells in a table. If the returned dataframe is empty it does not have any duplicate cells. Usage nz_find_duplicates ( DSN , table , limit = T ) Arguments Argument Description DSN Nz information object table table name in format of limit Whether to show all the duplicates or only show 100 result. It can cause performance issue on large tables if you set it to FALSE. Default is TRUE Value a sqlQuery object","title":"`nz_find_duplicates`: Find duplicates"},{"location":"Api/nz_find_duplicates/#nz_find_duplicates-find-duplicates","text":"","title":"nz_find_duplicates: Find duplicates"},{"location":"Api/nz_find_duplicates/#description","text":"Find duplicate cells in a table. If the returned dataframe is empty it does not have any duplicate cells.","title":"Description"},{"location":"Api/nz_find_duplicates/#usage","text":"nz_find_duplicates ( DSN , table , limit = T )","title":"Usage"},{"location":"Api/nz_find_duplicates/#arguments","text":"Argument Description DSN Nz information object table table name in format of limit Whether to show all the duplicates or only show 100 result. It can cause performance issue on large tables if you set it to FALSE. Default is TRUE","title":"Arguments"},{"location":"Api/nz_find_duplicates/#value","text":"a sqlQuery object","title":"Value"},{"location":"Api/nz_import_dir_to_db/","text":"nz_import_dir_to_db : import directory Description Import a directory into database. The directory must have a set of csv files Usage nz_import_dir_to_db ( DSN , directory , table_name , value_type = \"varchar\" , createTable = T , max_errors = 2 ) Arguments Argument Description DSN The NZ DSN object made by nz_init directory Directory of CSV files table_name Name of the table to import data into value_type The type of Value possible options float, varchar, integer, bigint createTable Either make a new table and drop table if exists or append data to the existing table max_errors The maximumn number of rows in the csv which can include error in their values Value Examples nz_import_dir_to_db()","title":"`nz_import_dir_to_db`: import directory"},{"location":"Api/nz_import_dir_to_db/#nz_import_dir_to_db-import-directory","text":"","title":"nz_import_dir_to_db: import directory"},{"location":"Api/nz_import_dir_to_db/#description","text":"Import a directory into database. The directory must have a set of csv files","title":"Description"},{"location":"Api/nz_import_dir_to_db/#usage","text":"nz_import_dir_to_db ( DSN , directory , table_name , value_type = \"varchar\" , createTable = T , max_errors = 2 )","title":"Usage"},{"location":"Api/nz_import_dir_to_db/#arguments","text":"Argument Description DSN The NZ DSN object made by nz_init directory Directory of CSV files table_name Name of the table to import data into value_type The type of Value possible options float, varchar, integer, bigint createTable Either make a new table and drop table if exists or append data to the existing table max_errors The maximumn number of rows in the csv which can include error in their values","title":"Arguments"},{"location":"Api/nz_import_dir_to_db/#value","text":"","title":"Value"},{"location":"Api/nz_import_dir_to_db/#examples","text":"nz_import_dir_to_db()","title":"Examples"},{"location":"Api/nz_import_file_to_db/","text":"nz_import_file_to_db : Import a file to db Description Import a single csv file to the netezza database. CSV columns must be as with following format \"VALUE\",\"DGGID\",\"TID\",\"KEY\" Usage nz_import_file_to_db ( DSN , file_path , table_name , value_type = \"varchar\" , createTable = T , max_errors = 2 ) Arguments Argument Description DSN object extracted from nz_init function file_path the csv file path with following format \"VALUE\",\"DGGID\",\"TID\",\"KEY\" value_type The type of Value possible options float, varchar, integer, bigint createTable Either make a new table and drop table if exists or append data to the existing table max_errors The maximumn number of rows in the csv which can include error in their values Value","title":"`nz_import_file_to_db`: Import a file to db"},{"location":"Api/nz_import_file_to_db/#nz_import_file_to_db-import-a-file-to-db","text":"","title":"nz_import_file_to_db: Import a file to db"},{"location":"Api/nz_import_file_to_db/#description","text":"Import a single csv file to the netezza database. CSV columns must be as with following format \"VALUE\",\"DGGID\",\"TID\",\"KEY\"","title":"Description"},{"location":"Api/nz_import_file_to_db/#usage","text":"nz_import_file_to_db ( DSN , file_path , table_name , value_type = \"varchar\" , createTable = T , max_errors = 2 )","title":"Usage"},{"location":"Api/nz_import_file_to_db/#arguments","text":"Argument Description DSN object extracted from nz_init function file_path the csv file path with following format \"VALUE\",\"DGGID\",\"TID\",\"KEY\" value_type The type of Value possible options float, varchar, integer, bigint createTable Either make a new table and drop table if exists or append data to the existing table max_errors The maximumn number of rows in the csv which can include error in their values","title":"Arguments"},{"location":"Api/nz_import_file_to_db/#value","text":"","title":"Value"},{"location":"Api/nz_init/","text":"nz_init : make nz db object Description Makes an Netezza db object for the user. Most of functions that need to interact with th netezza database need this object as input. Usage nz_init ( DSN_NAME , SCHEMA ) Arguments Argument Description DSN_NAME The DSN name for connection SCHEMA The database Schema Value an nz db object Examples obj <- nz_init ( \"NZSQL\" , \"SPATIAL_SCHEMA\" )","title":"`nz_init`: make nz db object"},{"location":"Api/nz_init/#nz_init-make-nz-db-object","text":"","title":"nz_init: make nz db object"},{"location":"Api/nz_init/#description","text":"Makes an Netezza db object for the user. Most of functions that need to interact with th netezza database need this object as input.","title":"Description"},{"location":"Api/nz_init/#usage","text":"nz_init ( DSN_NAME , SCHEMA )","title":"Usage"},{"location":"Api/nz_init/#arguments","text":"Argument Description DSN_NAME The DSN name for connection SCHEMA The database Schema","title":"Arguments"},{"location":"Api/nz_init/#value","text":"an nz db object","title":"Value"},{"location":"Api/nz_init/#examples","text":"obj <- nz_init ( \"NZSQL\" , \"SPATIAL_SCHEMA\" )","title":"Examples"},{"location":"Api/nz_make_centroids_df_from_csv/","text":"nz_make_centroids_df_from_csv : Generate Centroids Description Generate Centroid dataframe from a csv file with the following columns \"DGGID\",\"X\",\"Y\" Usage nz_make_centroids_df_from_csv ( csvpath ) Arguments Argument Description csvpath input csv file with the following columns \"DGGID\",\"X\",\"Y\" to reproject data you can use coord2=spTransform(coord2,CRS(\"+proj=laea +lon_0=0 +lat_0=90 +x_0=0 +y_0=0 +a=6378137 +rf=298.257223563\")) Value an object with the df parameter which is a df object of csv and a coords parameter which is an spatial dataframe object Examples","title":"`nz_make_centroids_df_from_csv`: Generate Centroids"},{"location":"Api/nz_make_centroids_df_from_csv/#nz_make_centroids_df_from_csv-generate-centroids","text":"","title":"nz_make_centroids_df_from_csv: Generate Centroids"},{"location":"Api/nz_make_centroids_df_from_csv/#description","text":"Generate Centroid dataframe from a csv file with the following columns \"DGGID\",\"X\",\"Y\"","title":"Description"},{"location":"Api/nz_make_centroids_df_from_csv/#usage","text":"nz_make_centroids_df_from_csv ( csvpath )","title":"Usage"},{"location":"Api/nz_make_centroids_df_from_csv/#arguments","text":"Argument Description csvpath input csv file with the following columns \"DGGID\",\"X\",\"Y\" to reproject data you can use coord2=spTransform(coord2,CRS(\"+proj=laea +lon_0=0 +lat_0=90 +x_0=0 +y_0=0 +a=6378137 +rf=298.257223563\"))","title":"Arguments"},{"location":"Api/nz_make_centroids_df_from_csv/#value","text":"an object with the df parameter which is a df object of csv and a coords parameter which is an spatial dataframe object","title":"Value"},{"location":"Api/nz_make_centroids_df_from_csv/#examples","text":"","title":"Examples"},{"location":"Api/nz_table_as_dplyr/","text":"nz_table_as_dplyr : Netezza Table To dplyr Description Converts a Netezza table to a dplyr object. Usage nz_table_as_dplyr ( DSN , tableName ) Arguments Argument Description DSN DSN object extracted from nz_init function tableName the name of the table to read Value A dplyr object Examples DSN <- nz_init ( \"NZSQL_F\" , \"ADMIN\" ) mbp <- nz_table_as_dplyr ( DSN , \"MPB\" ) head ( mbp )","title":"`nz_table_as_dplyr`: Netezza Table To dplyr"},{"location":"Api/nz_table_as_dplyr/#nz_table_as_dplyr-netezza-table-to-dplyr","text":"","title":"nz_table_as_dplyr: Netezza Table To dplyr"},{"location":"Api/nz_table_as_dplyr/#description","text":"Converts a Netezza table to a dplyr object.","title":"Description"},{"location":"Api/nz_table_as_dplyr/#usage","text":"nz_table_as_dplyr ( DSN , tableName )","title":"Usage"},{"location":"Api/nz_table_as_dplyr/#arguments","text":"Argument Description DSN DSN object extracted from nz_init function tableName the name of the table to read","title":"Arguments"},{"location":"Api/nz_table_as_dplyr/#value","text":"A dplyr object","title":"Value"},{"location":"Api/nz_table_as_dplyr/#examples","text":"DSN <- nz_init ( \"NZSQL_F\" , \"ADMIN\" ) mbp <- nz_table_as_dplyr ( DSN , \"MPB\" ) head ( mbp )","title":"Examples"},{"location":"Examples/GettingStarted/","text":"Getting Started In this example we try to connect to the Netezza and use IDEAS data model to perform a few simple analytics queries. library ( DBI ) library ( dplyr ) library ( sf ) library ( nzdggs ) # define init object and connection DSN = nz_init ( \"NZSQL\" , \"SPATIAL_SCHHEMA\" ) con = dbConnect ( RNetezza :: Netezza (), dsn = DSN $ DSN_NAME ) # query data data = tbl ( con , \"ANUSPLINE3\" ) datap = data %>% filter ( KEY == 'PRECIPITATION' ) # manipulate data datap = datap %>% mutate ( VALUE = VALUE +1 ) %>% show_query () # average them avgs = datap %>% group_by ( TID ) %>% arrange ( TID ) %>% summarise ( AVGS = mean ( VALUE )) %>% head ( 10 ) avgt = datap %>% group_by ( DGGID ) %>% summarise ( AVGT = mean ( VALUE )) # For plotting we get finalgrid grid = tbl ( con , \"FINALGRID2\" ) # join average with final grid on DGGID column out = avgt %>% inner_join ( grid , by = c ( 'DGGID' )) %>% mutate ( WKT = inza..ST_AsText ( GEOM )) %>% select ( DGGID , AVGT , WKT ) %>% arrange ( DGGID ) %>% head ( 100 ) %>% collect () # convert to sf object poly = st_as_sf ( out , wkt = 'WKT' , crs = 4326 ) #plot them plot ( poly [ 'AVGT' ]) head ( data )","title":"Getting Started"},{"location":"Examples/GettingStarted/#getting-started","text":"In this example we try to connect to the Netezza and use IDEAS data model to perform a few simple analytics queries. library ( DBI ) library ( dplyr ) library ( sf ) library ( nzdggs ) # define init object and connection DSN = nz_init ( \"NZSQL\" , \"SPATIAL_SCHHEMA\" ) con = dbConnect ( RNetezza :: Netezza (), dsn = DSN $ DSN_NAME ) # query data data = tbl ( con , \"ANUSPLINE3\" ) datap = data %>% filter ( KEY == 'PRECIPITATION' ) # manipulate data datap = datap %>% mutate ( VALUE = VALUE +1 ) %>% show_query () # average them avgs = datap %>% group_by ( TID ) %>% arrange ( TID ) %>% summarise ( AVGS = mean ( VALUE )) %>% head ( 10 ) avgt = datap %>% group_by ( DGGID ) %>% summarise ( AVGT = mean ( VALUE )) # For plotting we get finalgrid grid = tbl ( con , \"FINALGRID2\" ) # join average with final grid on DGGID column out = avgt %>% inner_join ( grid , by = c ( 'DGGID' )) %>% mutate ( WKT = inza..ST_AsText ( GEOM )) %>% select ( DGGID , AVGT , WKT ) %>% arrange ( DGGID ) %>% head ( 100 ) %>% collect () # convert to sf object poly = st_as_sf ( out , wkt = 'WKT' , crs = 4326 ) #plot them plot ( poly [ 'AVGT' ]) head ( data )","title":"Getting Started"},{"location":"Examples/IDEAS/IDEAS-spatial-overlay/","text":"Tutorial Overview This tutorial demonstrates some simple spatial overlay analysis of polygon data using the IDEAS data model, as described in Robertson et al. 2020. Preliminaries We will load some sample data from the stampr package, and pull out two polygons to demonstrate overlay operations. library ( stampr ) library ( sp ) data ( mpb ) P1 <- subset ( mpb , TGROUP == 1 )[ 5 ,] P2 <- subset ( mpb , TGROUP == 2 )[ 7 ,] plot ( P2 , border = \"green\" ) plot ( P1 , add = TRUE , border = \"blue\" ) First we need to load some libraries; library ( \"dplyr\" ) library ( \"dbplyr\" ) library ( \"DBI\" ) library ( \"leaflet\" ) library ( \"sf\" ) library ( \"RODBC\" ) library ( \"nzdggs\" ) Loading Polygon Data from IDEAS We will use the con data connection to access a table called mpb which has the same data from the stampr package in IDEAS format. mpb.i <- tbl ( con , \"MPB\" ) grid <- tbl ( con , \"FINALGRID2\" ) %>% filter ( RESOLUTION == 19 ) head ( mpb.i ) #> # Source: lazy query [?? x 4] #> # Database: NetezzaConnection #> DGGID VALUE KEY TID #> <dbl> <int> <chr> <int> #> 1 4921587640 1 BOUNDARY 1264 #> 2 4921646690 1 BOUNDARY 1264 #> 3 4921587640 0 ID 1264 #> 4 4921646690 0 ID 1264 #> 5 4921587640 1264 tid 1264 #> 6 4921646690 1264 tid 1264 We want to pull out those same two polygons by identifying them by their ID values, as follows: ID1 <- P1 $ ID ID2 <- P2 $ ID P1.i <- mpb.i %>% filter ( KEY == \"ID\" ) %>% filter ( VALUE == ID1 ) %>% inner_join ( . , grid , \"DGGID\" ) %>% mutate ( WKT = inza..ST_AsText ( GEOM )) %>% collect () P2.i <- mpb.i %>% filter ( KEY == \"ID\" ) %>% filter ( VALUE == ID2 ) %>% inner_join ( . , grid , \"DGGID\" ) %>% mutate ( WKT = inza..ST_AsText ( GEOM )) %>% collect () dbDisconnect ( con ) plot ( st_as_sf ( P2.i , wkt = 'WKT' , crs = 4326 )[ 'TID' ], col = 'green' , reset = FALSE ) plot ( st_as_sf ( P1.i , wkt = 'WKT' , crs = 4326 )[ 'TID' ], add = TRUE , col = 'blue' ) Overlay Analysis using IDEAS data model Intersection intersection <- P1.i %>% inner_join ( . , P2.i , \"DGGID\" ) plot ( st_as_sf ( P2.i , wkt = 'WKT' , crs = 4326 )[ 'TID' ], col = 'green' , reset = FALSE ) plot ( st_as_sf ( P1.i , wkt = 'WKT' , crs = 4326 )[ 'TID' ], add = TRUE , col = 'blue' ) plot ( st_as_sf ( intersection , wkt = 'WKT.x' , crs = 4326 )[ 'TID.x' ], add = TRUE , col = 'red' ) Union union <- union_all ( P1.i , P2.i ) %>% distinct ( DGGID , .keep_all = TRUE ) plot ( st_as_sf ( union , wkt = c ( 'WKT' ), crs = 4326 )[ 'TID' ], col = 'red' ) A NOT B ANotB <- P1.i %>% anti_join ( . , P2.i , \"DGGID\" ) plot ( st_as_sf ( P2.i , wkt = 'WKT' , crs = 4326 )[ 'TID' ], col = 'green' , reset = FALSE ) plot ( st_as_sf ( ANotB , wkt = c ( 'WKT' ), crs = 4326 )[ 'TID' ], add = TRUE , col = 'red' )","title":"IDEAS spatial overlay"},{"location":"Examples/IDEAS/IDEAS-spatial-overlay/#tutorial-overview","text":"This tutorial demonstrates some simple spatial overlay analysis of polygon data using the IDEAS data model, as described in Robertson et al. 2020.","title":"Tutorial Overview"},{"location":"Examples/IDEAS/IDEAS-spatial-overlay/#preliminaries","text":"We will load some sample data from the stampr package, and pull out two polygons to demonstrate overlay operations. library ( stampr ) library ( sp ) data ( mpb ) P1 <- subset ( mpb , TGROUP == 1 )[ 5 ,] P2 <- subset ( mpb , TGROUP == 2 )[ 7 ,] plot ( P2 , border = \"green\" ) plot ( P1 , add = TRUE , border = \"blue\" ) First we need to load some libraries; library ( \"dplyr\" ) library ( \"dbplyr\" ) library ( \"DBI\" ) library ( \"leaflet\" ) library ( \"sf\" ) library ( \"RODBC\" ) library ( \"nzdggs\" )","title":"Preliminaries"},{"location":"Examples/IDEAS/IDEAS-spatial-overlay/#loading-polygon-data-from-ideas","text":"We will use the con data connection to access a table called mpb which has the same data from the stampr package in IDEAS format. mpb.i <- tbl ( con , \"MPB\" ) grid <- tbl ( con , \"FINALGRID2\" ) %>% filter ( RESOLUTION == 19 ) head ( mpb.i ) #> # Source: lazy query [?? x 4] #> # Database: NetezzaConnection #> DGGID VALUE KEY TID #> <dbl> <int> <chr> <int> #> 1 4921587640 1 BOUNDARY 1264 #> 2 4921646690 1 BOUNDARY 1264 #> 3 4921587640 0 ID 1264 #> 4 4921646690 0 ID 1264 #> 5 4921587640 1264 tid 1264 #> 6 4921646690 1264 tid 1264 We want to pull out those same two polygons by identifying them by their ID values, as follows: ID1 <- P1 $ ID ID2 <- P2 $ ID P1.i <- mpb.i %>% filter ( KEY == \"ID\" ) %>% filter ( VALUE == ID1 ) %>% inner_join ( . , grid , \"DGGID\" ) %>% mutate ( WKT = inza..ST_AsText ( GEOM )) %>% collect () P2.i <- mpb.i %>% filter ( KEY == \"ID\" ) %>% filter ( VALUE == ID2 ) %>% inner_join ( . , grid , \"DGGID\" ) %>% mutate ( WKT = inza..ST_AsText ( GEOM )) %>% collect () dbDisconnect ( con ) plot ( st_as_sf ( P2.i , wkt = 'WKT' , crs = 4326 )[ 'TID' ], col = 'green' , reset = FALSE ) plot ( st_as_sf ( P1.i , wkt = 'WKT' , crs = 4326 )[ 'TID' ], add = TRUE , col = 'blue' )","title":"Loading Polygon Data from IDEAS"},{"location":"Examples/IDEAS/IDEAS-spatial-overlay/#overlay-analysis-using-ideas-data-model","text":"","title":"Overlay Analysis using IDEAS data model"},{"location":"Examples/IDEAS/IDEAS-spatial-overlay/#intersection","text":"intersection <- P1.i %>% inner_join ( . , P2.i , \"DGGID\" ) plot ( st_as_sf ( P2.i , wkt = 'WKT' , crs = 4326 )[ 'TID' ], col = 'green' , reset = FALSE ) plot ( st_as_sf ( P1.i , wkt = 'WKT' , crs = 4326 )[ 'TID' ], add = TRUE , col = 'blue' ) plot ( st_as_sf ( intersection , wkt = 'WKT.x' , crs = 4326 )[ 'TID.x' ], add = TRUE , col = 'red' )","title":"Intersection"},{"location":"Examples/IDEAS/IDEAS-spatial-overlay/#union","text":"union <- union_all ( P1.i , P2.i ) %>% distinct ( DGGID , .keep_all = TRUE ) plot ( st_as_sf ( union , wkt = c ( 'WKT' ), crs = 4326 )[ 'TID' ], col = 'red' )","title":"Union"},{"location":"Examples/IDEAS/IDEAS-spatial-overlay/#a-not-b","text":"ANotB <- P1.i %>% anti_join ( . , P2.i , \"DGGID\" ) plot ( st_as_sf ( P2.i , wkt = 'WKT' , crs = 4326 )[ 'TID' ], col = 'green' , reset = FALSE ) plot ( st_as_sf ( ANotB , wkt = c ( 'WKT' ), crs = 4326 )[ 'TID' ], add = TRUE , col = 'red' )","title":"A NOT B"},{"location":"Examples/IDEAS/IDEAS_Analytics/","text":"Integrated Discrete Environmental Analytics System Chiranjib Chaudhuri 2020-07-01 GitHub Documents This document explains the analytic capabilities of the IDEAS data model. ## ## Attaching package : 'dplyr' ## The following objects are masked from 'package:stats' : ## ## filter , lag ## The following objects are masked from 'package:base' : ## ## intersect , setdiff , setequal , union ## Linking to GEOS 3 . 8 . 0 , GDAL 2 . 5 . 0 , PROJ 6 . 3 . 0 We connect to a table containing spatial-time series of annual extreme daily climate variables for entire Canada. data = tbl ( con , \"ANUSPLINE3\" ) head ( data ) ## # Source: lazy query [?? x 4] ## # Database: NetezzaConnection ## DGGID KEY VALUE TID ## <int> <chr> <dbl> <int> ## 1 2420704 MAX_TEMP 20.4 1950 ## 2 2374744 MAX_TEMP 23.5 1950 ## 3 2360784 MAX_TEMP 27.0 1950 ## 4 2364464 MAX_TEMP 25.6 1950 ## 5 2311463 MAX_TEMP 30.7 1950 ## 6 2381424 MAX_TEMP 20.5 1950 Next we slice the data set for annual maximum daily precipitation. datap = data %>% filter ( KEY == 'PRECIPITATION' ) head ( datap ) ## # Source: lazy query [?? x 4] ## # Database: NetezzaConnection ## DGGID KEY VALUE TID ## <int> <chr> <dbl> <int> ## 1 2297589 PRECIPITATION 7.00 1950 ## 2 2473831 PRECIPITATION 18.1 1950 ## 3 2393550 PRECIPITATION 24.5 1950 ## 4 2479111 PRECIPITATION 5.10 1950 ## 5 2417910 PRECIPITATION 5.45 1950 ## 6 2493712 PRECIPITATION 11.5 1950 We will calculate time-series of spatial average avgs = datap %>% group_by ( TID ) %>% arrange ( TID ) %>% summarise ( VALUE = mean ( VALUE )) head ( avgs ) ## Warning : Missing values are always removed in SQL . ## Use ` mean ( x , na . rm = TRUE ) ` to silence this warning ## This warning is displayed only once per session . ## # Source : lazy query [ ?? x 2 ] ## # Database : NetezzaConnection ## TID VALUE ## < int > < dbl > ## 1 1950 17 . 7 ## 2 1951 18 . 0 ## 3 1952 19 . 6 ## 4 1953 20 . 9 ## 5 1954 21 . 1 ## 6 1955 20 . 1 We will calculate spatial distribution of temporal average avgt = datap %>% group_by ( DGGID ) %>% arrange ( DGGID ) %>% summarise ( VALUE = mean ( VALUE )) head ( avgt ) ## # Source: lazy query [?? x 2] ## # Database: NetezzaConnection ## DGGID VALUE ## <int> <dbl> ## 1 2460666 26.7 ## 2 2277703 27.6 ## 3 2414025 24.7 ## 4 2481826 26.2 ## 5 2266103 34.0 ## 6 2292943 40.3 Let us plot some of these basic variables. avgs = collect ( avgs ) plot ( avgs $ TID , avgs $ VALUE ) To plot the spatial variable we need to attach it with the spatial tabls. grid = tbl ( con , \"FINALGRID2\" ) head ( grid ) ## # Source: lazy query [?? x 6] ## # Database: NetezzaConnection ## DGGID RESOLUTION QUAD I J GEOM ## <dbl> <int> <int> <int> <int> <ODBC_bnr> ## 1 1.38e11 22 5 68729 95619 010100f0e599f2bc145bc06412aaabad145bc\u2026 ## 2 1.38e11 22 5 68733 95613 010100b495fa264b145bc0ec7e15e03b145bc\u2026 ## 3 1.38e11 22 5 68732 95610 0101009cc6accd35145bc02ce6e78626145bc\u2026 ## 4 1.38e11 22 5 68733 95597 01010068a8401c9a135bc0a434bcd58a135bc\u2026 ## 5 1.38e11 22 5 68726 95603 0101008cd03a702f145bc000a0ab2920145bc\u2026 ## 6 1.38e11 22 5 68728 95595 01010004a6fc39bf135bc0986898f3af135bc\u2026 avgt = avgt %>% inner_join ( grid , by = c ( 'DGGID' )) %>% mutate ( WKT = inza..ST_AsText ( GEOM )) %>% select ( DGGID , VALUE , WKT ) %>% arrange ( DGGID ) %>% head ( 100 ) %>% collect () poly = st_as_sf ( avgt , wkt = 'WKT' , crs = 4326 ) plot ( poly [ 'VALUE' ]) Lets get a little more complex now. We want to clip the data for one of the eco-zone over Canada say somwhere over BC, Pacific-Maritime (ecozone=13) ecozone = tbl ( con , \"ECOZONE_12\" ) %>% filter ( VALUE == 13 ) %>% select ( DGGID ) head ( ecozone ) ## # Source: lazy query [?? x 1] ## # Database: NetezzaConnection ## DGGID ## <int> ## 1 2290293 ## 2 2290292 ## 3 2212852 ## 4 2213587 ## 5 2214331 ## 6 2216513 datape = datap %>% inner_join ( ecozone , by = c ( 'DGGID' )) head ( datape ) ## # Source: lazy query [?? x 4] ## # Database: NetezzaConnection ## DGGID KEY VALUE TID ## <int> <chr> <dbl> <int> ## 1 2222341 PRECIPITATION 89.3 1950 ## 2 2222341 PRECIPITATION 89.3 1950 ## 3 2231102 PRECIPITATION 34.2 1950 ## 4 2231102 PRECIPITATION 34.2 1950 ## 5 2233302 PRECIPITATION 25.0 1950 ## 6 2233302 PRECIPITATION 25.0 1950","title":"IDEAS Analytics"},{"location":"Examples/IDEAS/IDEAS_Analytics/#integrated-discrete-environmental-analytics-system","text":"Chiranjib Chaudhuri 2020-07-01","title":"Integrated Discrete Environmental Analytics System"},{"location":"Examples/IDEAS/IDEAS_Analytics/#github-documents","text":"This document explains the analytic capabilities of the IDEAS data model. ## ## Attaching package : 'dplyr' ## The following objects are masked from 'package:stats' : ## ## filter , lag ## The following objects are masked from 'package:base' : ## ## intersect , setdiff , setequal , union ## Linking to GEOS 3 . 8 . 0 , GDAL 2 . 5 . 0 , PROJ 6 . 3 . 0 We connect to a table containing spatial-time series of annual extreme daily climate variables for entire Canada. data = tbl ( con , \"ANUSPLINE3\" ) head ( data ) ## # Source: lazy query [?? x 4] ## # Database: NetezzaConnection ## DGGID KEY VALUE TID ## <int> <chr> <dbl> <int> ## 1 2420704 MAX_TEMP 20.4 1950 ## 2 2374744 MAX_TEMP 23.5 1950 ## 3 2360784 MAX_TEMP 27.0 1950 ## 4 2364464 MAX_TEMP 25.6 1950 ## 5 2311463 MAX_TEMP 30.7 1950 ## 6 2381424 MAX_TEMP 20.5 1950 Next we slice the data set for annual maximum daily precipitation. datap = data %>% filter ( KEY == 'PRECIPITATION' ) head ( datap ) ## # Source: lazy query [?? x 4] ## # Database: NetezzaConnection ## DGGID KEY VALUE TID ## <int> <chr> <dbl> <int> ## 1 2297589 PRECIPITATION 7.00 1950 ## 2 2473831 PRECIPITATION 18.1 1950 ## 3 2393550 PRECIPITATION 24.5 1950 ## 4 2479111 PRECIPITATION 5.10 1950 ## 5 2417910 PRECIPITATION 5.45 1950 ## 6 2493712 PRECIPITATION 11.5 1950 We will calculate time-series of spatial average avgs = datap %>% group_by ( TID ) %>% arrange ( TID ) %>% summarise ( VALUE = mean ( VALUE )) head ( avgs ) ## Warning : Missing values are always removed in SQL . ## Use ` mean ( x , na . rm = TRUE ) ` to silence this warning ## This warning is displayed only once per session . ## # Source : lazy query [ ?? x 2 ] ## # Database : NetezzaConnection ## TID VALUE ## < int > < dbl > ## 1 1950 17 . 7 ## 2 1951 18 . 0 ## 3 1952 19 . 6 ## 4 1953 20 . 9 ## 5 1954 21 . 1 ## 6 1955 20 . 1 We will calculate spatial distribution of temporal average avgt = datap %>% group_by ( DGGID ) %>% arrange ( DGGID ) %>% summarise ( VALUE = mean ( VALUE )) head ( avgt ) ## # Source: lazy query [?? x 2] ## # Database: NetezzaConnection ## DGGID VALUE ## <int> <dbl> ## 1 2460666 26.7 ## 2 2277703 27.6 ## 3 2414025 24.7 ## 4 2481826 26.2 ## 5 2266103 34.0 ## 6 2292943 40.3 Let us plot some of these basic variables. avgs = collect ( avgs ) plot ( avgs $ TID , avgs $ VALUE ) To plot the spatial variable we need to attach it with the spatial tabls. grid = tbl ( con , \"FINALGRID2\" ) head ( grid ) ## # Source: lazy query [?? x 6] ## # Database: NetezzaConnection ## DGGID RESOLUTION QUAD I J GEOM ## <dbl> <int> <int> <int> <int> <ODBC_bnr> ## 1 1.38e11 22 5 68729 95619 010100f0e599f2bc145bc06412aaabad145bc\u2026 ## 2 1.38e11 22 5 68733 95613 010100b495fa264b145bc0ec7e15e03b145bc\u2026 ## 3 1.38e11 22 5 68732 95610 0101009cc6accd35145bc02ce6e78626145bc\u2026 ## 4 1.38e11 22 5 68733 95597 01010068a8401c9a135bc0a434bcd58a135bc\u2026 ## 5 1.38e11 22 5 68726 95603 0101008cd03a702f145bc000a0ab2920145bc\u2026 ## 6 1.38e11 22 5 68728 95595 01010004a6fc39bf135bc0986898f3af135bc\u2026 avgt = avgt %>% inner_join ( grid , by = c ( 'DGGID' )) %>% mutate ( WKT = inza..ST_AsText ( GEOM )) %>% select ( DGGID , VALUE , WKT ) %>% arrange ( DGGID ) %>% head ( 100 ) %>% collect () poly = st_as_sf ( avgt , wkt = 'WKT' , crs = 4326 ) plot ( poly [ 'VALUE' ]) Lets get a little more complex now. We want to clip the data for one of the eco-zone over Canada say somwhere over BC, Pacific-Maritime (ecozone=13) ecozone = tbl ( con , \"ECOZONE_12\" ) %>% filter ( VALUE == 13 ) %>% select ( DGGID ) head ( ecozone ) ## # Source: lazy query [?? x 1] ## # Database: NetezzaConnection ## DGGID ## <int> ## 1 2290293 ## 2 2290292 ## 3 2212852 ## 4 2213587 ## 5 2214331 ## 6 2216513 datape = datap %>% inner_join ( ecozone , by = c ( 'DGGID' )) head ( datape ) ## # Source: lazy query [?? x 4] ## # Database: NetezzaConnection ## DGGID KEY VALUE TID ## <int> <chr> <dbl> <int> ## 1 2222341 PRECIPITATION 89.3 1950 ## 2 2222341 PRECIPITATION 89.3 1950 ## 3 2231102 PRECIPITATION 34.2 1950 ## 4 2231102 PRECIPITATION 34.2 1950 ## 5 2233302 PRECIPITATION 25.0 1950 ## 6 2233302 PRECIPITATION 25.0 1950","title":"GitHub Documents"},{"location":"Examples/ImportData/convert_csv_to_dggs/","text":"Convert and Importing Data Converting a csv file of lat,lon points to DGGS data model r <- read.csv ( 'D:/Bathurst_caribou_collars.csv' ) nz_convert_points_df_to_dggs ( r $ Latitude , r $ Latitude , 10 , 20 , r , \"C:/result\" ) Lat/Lon To DGGS Converting and importing a csv to the netezza #Assume we have a csv file with following columns. X,DGGID,EVENT (two keys) csv <- read.csv2 ( \"mpb-ev.csv\" , sep = \",\" ) head ( csv ) X DGGID EVENT 1 1 14772025795 CONTR 2 2 14772084845 CONTR 3 3 14772084846 CONTR 4 4 14772143895 CONTR 5 5 14772143896 CONTR 6 6 14772143897 CONTR #Make a dataframe with following columns. The order of columns are important df <- data.frame ( VALUE = csv $ EVENT , DGGID = csv $ DGGID , TID = rep ( -1 , length ( csv $ DGGID )), KEY = rep ( \"EVENT\" , length ( csv $ DGGID ))) #save the dataframe as a csv with row.names=F and seperator =\",\" . Use write.csv instead of write.csv2 write.csv ( df , row.names = F , \"import//event.csv\" , sep = \",\" ) #another dataframe for the second key df2 <- data.frame ( VALUE = csv $ X , DGGID = csv $ DGGID , TID = rep ( -1 , length ( csv $ DGGID )), KEY = rep ( \"ID\" , length ( csv $ DGGID ))) #save in the same folder with diffrent name write.csv ( df2 , row.names = F , \"import//id.csv\" , sep = \",\" ) #init DSN object for data import. Define SCHEMA based on your user DSN <- nz_init ( \"NZSQL\" , \"SCHEMA\" ) #impord data from folder to the database. The key type is varchar(100) for multiple keys. nz_import_dir_to_db ( DSN , \"/home/[user]/import/\" , \"mbpev\" , \"varchar(100)\" )","title":"Convert and Importing Data"},{"location":"Examples/ImportData/convert_csv_to_dggs/#convert-and-importing-data","text":"Converting a csv file of lat,lon points to DGGS data model r <- read.csv ( 'D:/Bathurst_caribou_collars.csv' ) nz_convert_points_df_to_dggs ( r $ Latitude , r $ Latitude , 10 , 20 , r , \"C:/result\" )","title":"Convert and Importing Data"},{"location":"Examples/ImportData/convert_csv_to_dggs/#latlon-to-dggs","text":"Converting and importing a csv to the netezza #Assume we have a csv file with following columns. X,DGGID,EVENT (two keys) csv <- read.csv2 ( \"mpb-ev.csv\" , sep = \",\" ) head ( csv ) X DGGID EVENT 1 1 14772025795 CONTR 2 2 14772084845 CONTR 3 3 14772084846 CONTR 4 4 14772143895 CONTR 5 5 14772143896 CONTR 6 6 14772143897 CONTR #Make a dataframe with following columns. The order of columns are important df <- data.frame ( VALUE = csv $ EVENT , DGGID = csv $ DGGID , TID = rep ( -1 , length ( csv $ DGGID )), KEY = rep ( \"EVENT\" , length ( csv $ DGGID ))) #save the dataframe as a csv with row.names=F and seperator =\",\" . Use write.csv instead of write.csv2 write.csv ( df , row.names = F , \"import//event.csv\" , sep = \",\" ) #another dataframe for the second key df2 <- data.frame ( VALUE = csv $ X , DGGID = csv $ DGGID , TID = rep ( -1 , length ( csv $ DGGID )), KEY = rep ( \"ID\" , length ( csv $ DGGID ))) #save in the same folder with diffrent name write.csv ( df2 , row.names = F , \"import//id.csv\" , sep = \",\" ) #init DSN object for data import. Define SCHEMA based on your user DSN <- nz_init ( \"NZSQL\" , \"SCHEMA\" ) #impord data from folder to the database. The key type is varchar(100) for multiple keys. nz_import_dir_to_db ( DSN , \"/home/[user]/import/\" , \"mbpev\" , \"varchar(100)\" )","title":"Lat/Lon To DGGS"},{"location":"Examples/ImportData/convert_polygon_to_dggs/","text":"Polygon To DGGS Converting a Polygon shape file to DGGS datamodel using sampling. setwd ( 'D:/UserData/PLOTS' ) zones = readOGR ( \"ecozones.shp\" ) for ( i in seq ( 1 , 24 )){ print ( i ) z = zones [ i ,] nz_convert_polygon_to_dggs ( z , 12 , 12 , i , 'D:/UserData/Majid/upload' ) } #import data to db under Admin schema dsn <- nz_init ( \"NZSQLF\" , \"ADMIN\" ) nz_import_dir_to_db ( dsn , \"D:/UserData/Majid/Desktop/PLOTS/upload/\" , \"ECOZONE\" , 'varchar(100)' , T ) another example library ( \"nzdggs\" ) library ( \"stampr\" ) data ( mpb ) mpb $ dt <- Sys.Date () mpb $ YR <- mpb $ TGROUP +1996 mpb $ dt <- as.Date ( paste ( mpb $ YR , '-01-01' , sep = \"\" ), \"%Y-%m-%d\" ) mpb $ tid <- nz_convert_datetime_to_tid ( mpb $ dt , '1y' ) proj4string ( mpb ) <- '+proj=aea +lat_1=50 +lat_2=58.5 +lat_0=45 +lon_0=-126 +x_0=1000000 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs' mpb <- spTransform ( mpb , CRS ( \"+init=epsg:4326\" )) mpb <- mpb [, c ( 1 , 6 )] for ( i in seq ( 1 , length ( mpb ))){ z = mpb [ i ,] nz_convert_polygon_to_dggs ( z , 20 , z $ tid , z $ ID , \"E:\\\\home\\\\crobertson\\\\\" ) } DSN <- nz_init ( \"NZSQL_F\" , \"SPATIAL_SCHEMA\" ) nz_import_file_to_db ( DSN , \"E:/home/crobertson/cmb/cmb.csv\" , \"mpb\" , \"double\" , T , max_errors = 4400 )","title":"Polygon To DGGS"},{"location":"Examples/ImportData/convert_polygon_to_dggs/#polygon-to-dggs","text":"Converting a Polygon shape file to DGGS datamodel using sampling. setwd ( 'D:/UserData/PLOTS' ) zones = readOGR ( \"ecozones.shp\" ) for ( i in seq ( 1 , 24 )){ print ( i ) z = zones [ i ,] nz_convert_polygon_to_dggs ( z , 12 , 12 , i , 'D:/UserData/Majid/upload' ) } #import data to db under Admin schema dsn <- nz_init ( \"NZSQLF\" , \"ADMIN\" ) nz_import_dir_to_db ( dsn , \"D:/UserData/Majid/Desktop/PLOTS/upload/\" , \"ECOZONE\" , 'varchar(100)' , T )","title":"Polygon To DGGS"},{"location":"Examples/ImportData/convert_polygon_to_dggs/#another-example","text":"library ( \"nzdggs\" ) library ( \"stampr\" ) data ( mpb ) mpb $ dt <- Sys.Date () mpb $ YR <- mpb $ TGROUP +1996 mpb $ dt <- as.Date ( paste ( mpb $ YR , '-01-01' , sep = \"\" ), \"%Y-%m-%d\" ) mpb $ tid <- nz_convert_datetime_to_tid ( mpb $ dt , '1y' ) proj4string ( mpb ) <- '+proj=aea +lat_1=50 +lat_2=58.5 +lat_0=45 +lon_0=-126 +x_0=1000000 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs' mpb <- spTransform ( mpb , CRS ( \"+init=epsg:4326\" )) mpb <- mpb [, c ( 1 , 6 )] for ( i in seq ( 1 , length ( mpb ))){ z = mpb [ i ,] nz_convert_polygon_to_dggs ( z , 20 , z $ tid , z $ ID , \"E:\\\\home\\\\crobertson\\\\\" ) } DSN <- nz_init ( \"NZSQL_F\" , \"SPATIAL_SCHEMA\" ) nz_import_file_to_db ( DSN , \"E:/home/crobertson/cmb/cmb.csv\" , \"mpb\" , \"double\" , T , max_errors = 4400 )","title":"another example"},{"location":"Examples/ImportData/import_nc_file/","text":".Nc to DGGS Importing .nc files into db using centroids of resolution 9 library ( rgdal ) library ( raster ) library ( rgeos ) library ( sp ) library ( dggridR ) library ( ncdf4 ) library ( nzdggs ) dir <- \"F:\\\\carbon_emissions_landuse\\\\\" setwd ( dir ) cnt <- nz_make_centroids_df_from_csv ( \"F:\\\\Converter\\\\centroids\\\\res9_centroids.csv\" ) files = list.files ( pattern = \".nc\" ) create_table <- T for ( f in files ) { rast = raster ( f ) year <- 1850 for ( i in seq ( 1 , 156 )){ rast = raster ( f , varname = \"carbon_emission\" , band = i ) tid <- nz_convert_datetime_to_tid ( strptime ( paste ( '02-01-' , year , ' 00:00:00' , sep = \"\" ), \"%d-%m-%Y %H:%M:%S\" ), '1y' ) res_df <- nz_convert_raster_to_dggs_by_centroid ( rast , cnt , \"carbon_emission\" , tid ) name = paste ( year , '.csv' , sep = \"\" ) write.csv ( res_df , name , row.names = FALSE ) print ( name ) nz_import_file_to_db ( \"NZSQL_M\" , paste ( \"F:\\\\carbon_emissions_landuse\\\\\" , name , sep = \"\" ), \"CARBONEMISSIONS\" , value_type = \"double\" , createTable = create_table ) file.remove ( paste ( \"F:\\\\carbon_emissions_landuse\\\\\" , name , sep = \"\" )) year <- year + 1 create_table <- F } }","title":".Nc to DGGS"},{"location":"Examples/ImportData/import_nc_file/#nc-to-dggs","text":"Importing .nc files into db using centroids of resolution 9 library ( rgdal ) library ( raster ) library ( rgeos ) library ( sp ) library ( dggridR ) library ( ncdf4 ) library ( nzdggs ) dir <- \"F:\\\\carbon_emissions_landuse\\\\\" setwd ( dir ) cnt <- nz_make_centroids_df_from_csv ( \"F:\\\\Converter\\\\centroids\\\\res9_centroids.csv\" ) files = list.files ( pattern = \".nc\" ) create_table <- T for ( f in files ) { rast = raster ( f ) year <- 1850 for ( i in seq ( 1 , 156 )){ rast = raster ( f , varname = \"carbon_emission\" , band = i ) tid <- nz_convert_datetime_to_tid ( strptime ( paste ( '02-01-' , year , ' 00:00:00' , sep = \"\" ), \"%d-%m-%Y %H:%M:%S\" ), '1y' ) res_df <- nz_convert_raster_to_dggs_by_centroid ( rast , cnt , \"carbon_emission\" , tid ) name = paste ( year , '.csv' , sep = \"\" ) write.csv ( res_df , name , row.names = FALSE ) print ( name ) nz_import_file_to_db ( \"NZSQL_M\" , paste ( \"F:\\\\carbon_emissions_landuse\\\\\" , name , sep = \"\" ), \"CARBONEMISSIONS\" , value_type = \"double\" , createTable = create_table ) file.remove ( paste ( \"F:\\\\carbon_emissions_landuse\\\\\" , name , sep = \"\" )) year <- year + 1 create_table <- F } }","title":".Nc to DGGS"}]}